---
title: "Assignment 4 - Measuring movements"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(data.table)
library(rpart)
library(randomForest)
library(knitr)
```

##Goal 
Goal of the project is to predict how participants performed a barbell lifts correctly, based on the activity measured by the accelorometers on the belt, forearm, arm and dumbell. 

##Method
For this project, a training set is used from http://groupware.les.inf.puc-rio.br/har. This dataset consists of 160 variables and 19622 variables.

Cleaning up the data is done by removing the columns that contain values which that only have one unique value or columns that have a very few unique values relative to the number of samples. Next to that, the columns which contain NA-values are removed from the dataset.
As the dataset contains columns which should not be used for the model (identifier columns, names of the participants, time), these columns are removed from the dataset. After cleaning up, there are 53 columns left.

After cleaning up the data, the data is split up in a training set (3/4 of the dataset) and a test set (1/4 of the dataset) which is used for cross validation.

The model will be build on the training set and tested on the testset (the 1/4 part of the original training set).

```{r cars}
#load dataset
setwd("~/coursera")
pmltraining<-read.csv("pml-training.csv")

#create dataframe columns with nearzerovalues
nzvar<-as.data.frame(nearZeroVar(pmltraining,names=TRUE,saveMetrics = FALSE))

#rename the column
colnames(nzvar)<-c("column")

#subset data, only columns that are not in the nearzerovalues
data<-pmltraining[,-which(names(pmltraining) %in% nzvar$column)]
rm(nzvar)

#subset data, only columns that do not contain NA-values
navar<-as.data.frame(names(which(sapply(data, anyNA))))
colnames(navar)<-c("column")

data<-data[,-which(names(data) %in% navar$column)]
rm(navar)

#remove columns that should not be used (the identifier column, name of participants, the time)
idvar <- as.data.frame(grep("X|name|timestamp|window", colnames(data), value=T)) 
colnames(idvar)<-c("column")

data<-data[,-which(names(data) %in% idvar$column)]
rm(idvar)

#split data in trainin and testset
inTrain = createDataPartition(data$classe, p = 3/4)[[1]]

training = data[ inTrain,]
testing = data[-inTrain,]
rm(inTrain)
```

The created trainingset consists of `r nrow(training)` rows. The created testset consists of `r nrow(testing)` rows. The datasets consists of 53 columns of which 1 is the column 'classe'.

Two models are created. First, a decision tree model is trained, with the rpart package. Next to that a random forest model is trained with the randomForest package. After training the model, the model is applied to the training set, to find out how many of the results are predicted correctly by the model. The confusion matrices and accuracy of both models will be used to choose the final model.

##Model
```{r}
#create a model (decision tree)
modeldt<-rpart(classe~., data=training, method = "class")

#use the model to predict the results of the training set
preddt<-predict(modeldt, training, type="class")

#create confusion matrix and calculate the accuracy
cmdt<-table(training$classe,preddt)
accdt<-sum(diag(cmdt))/sum(cmdt)

#create a model with caret package ()
modelrf<-randomForest(classe~., data=training)
predrf<-predict(modelrf, training, type="class")

#create confusion matrix and calculate the accuracy
cmrf<-table(training$classe,predrf)
accrf<-mean(predrf == training$classe)

```

The decision tree model generates a decision tree. This model is shown below.

```{r}
#plot the decision tree
plot <- plot(modeldt, uniform=TRUE, 
  	main="Classification Tree for Classe")
text(modeldt, use.n=FALSE, all=TRUE, cex=.6)
```

Below, the confusion matrices from the both models are shown.  The rows show the reference values (the original values), the columns show the predicted values. The decision tree model has an accuracy of `r accdt`, the random forest model has an accuracy of `r accrf`. 

```{r}
cmdt %>% kable(caption = "Confusion Matrix Decision Tree Model")
cmrf %>% kable(caption = "Confusion Matrix Random Forest Model")
```

As the random forest model has a perfect accuracy, we choose this model. 

The next step is to use the model for predicting the classe on the test set. In this way, we can find out how well the trained model performs on a new dataset. In order to to this, we apply the model trained on the training set to the test set and have a look at the confusion matrix and the accuracy.

```{r}
#predict values
predrftest<-predict(modelrf, testing, type="class")

#show confusion matrix and calculate the accuracy
cmrftest<-table(testing$classe,predrftest)
accrftest<-mean(predrftest == testing$classe)
```

Below, the confusion matrix from the random tree model on the testing set is shown. This model has an accuracy of `r accrftest` on the testing set.

```{r}
cmrftest %>% kable(caption = "Confusion matrix on test set")
```

#Conclusion
The random forest model which is trained on the training set performs well on the test set. Because of that, we conclude that this model can be used for predicting how participants performed a barbell lifts.